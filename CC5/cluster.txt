1) deploy flink operator

a) build custom flink operator image with docker
docker build -t inessntr/cloudcomputing:customFlinkOperatorImage -f customFlinkOperatorImage.Dockerfile .
docker push inessntr/cloudcomputing:customFlinkOperatorImage

b) deploy flink operator on cluster
kubectl create -f https://github.com/jetstack/cert-manager/releases/download/v1.8.2/cert-manager.yaml
helm repo add flink-operator-repo https://downloads.apache.org/flink/flink-kubernetes-operator-1.3.1/
helm install --set image.repository=inessntr/cloudcomputing --set image.tag=customFlinkOperatorImage flink-kubernetes-operator flink-operator-repo/flink-kubernetes-operator

2) HADOOP

git clone https://github.com/helm/charts.git
cd charts
helm install \
    --set yarn.nodeManager.resources.limits.memory=4096Mi \
    --set yarn.nodeManager.replicas=1 \
    hadoop \
    stable/hadoop

3) Deploy flink job

a) build custom flink image 
docker build -t inessntr/cloudcomputing:customFlinkImage -f customFlinkImage.Dockerfile .
docker push inessntr/cloudcomputing:customFlinkImage

b) upload to VMs
scp -i ~/.ssh/id_rsa loglevelcountdeploymentandjob.yml id_rsa@xx.xx.xx.xx:.
scp -i ~/.ssh/id_rsa zookeeper_logs.txt id_rsa@xx.xx.xx.xx:.

c) upload to HDFS
kubectl cp zookeeper_logs.txt "hadoop-hadoop-yarn-nm-0":/home
kubectl exec -it "hadoop-hadoop-yarn-nm-0" bash
cd /home
mkdir input
mv zookeeper_logs.txt input/
/usr/local/hadoop/bin/hadoop fs -put input /
/usr/local/hadoop/bin/hadoop fs -chmod -R 777 /input

d) deploy job
kubectl create -f loglevelcountdeploymentandjob.yml
